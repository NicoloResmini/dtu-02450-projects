{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Import and standardize datas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.pyplot import (figure, title, boxplot, xticks, subplot, hist,\n",
    "                               xlabel, ylim, yticks, show, savefig)\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('hour.csv')\n",
    "\n",
    "# PREPROCESSING\n",
    "\n",
    "# Removing useless attributes\n",
    "df = df.drop('dteday', axis=1)\n",
    "df = df.drop('instant', axis=1)\n",
    "df = df.drop('yr', axis=1)\n",
    "\n",
    "\n",
    "# Applying sqrt to \"cnt\" (to make it a continuous variable)\n",
    "df['cnt'] = np.sqrt(df['cnt'])\n",
    "\n",
    "# Removing deprecated attributes after the sqrt transformation (cnt = casual + registered)\n",
    "df = df.drop('casual', axis=1)\n",
    "df = df.drop('registered', axis=1)\n",
    "df = df.drop('atemp', axis=1)\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_full = df.values\n",
    "scaler = StandardScaler()\n",
    "X_full_scaled = scaler.fit_transform(X_full)\n",
    "df = pd.DataFrame(X_full_scaled, columns=df.columns)\n",
    "\n",
    "X = df.drop(columns=['cnt']).values\n",
    "attributeNames = df.columns.drop(['cnt']).tolist()\n",
    "N, M = X.shape\n",
    "y = df['cnt'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6468675\t0.0011585588\n",
      "\t\t2000\t0.5152829\t1.0988873e-05\n",
      "\t\t3000\t0.5109396\t5.4828456e-06\n",
      "\t\t4000\t0.5091301\t1.9902122e-06\n",
      "\t\tFinal loss:\n",
      "\t\t4624\t0.50862086\t9.375091e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.30517632\t0.00025891687\n",
      "\t\t2000\t0.19890647\t0.00045527838\n",
      "\t\t3000\t0.1499379\t0.00017100756\n",
      "\t\t4000\t0.1325158\t0.000120080236\n",
      "\t\t5000\t0.11141046\t0.00013072364\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.11141046\t0.00013072364\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.29692453\t0.00033592596\n",
      "\t\t2000\t0.1630978\t0.00087376585\n",
      "\t\t3000\t0.10679551\t0.0001923049\n",
      "\t\t4000\t0.09154221\t0.00012646339\n",
      "\t\t5000\t0.08244251\t8.394951e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.08244251\t8.394951e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.26310423\t0.00040851816\n",
      "\t\t2000\t0.13068116\t0.0005161611\n",
      "\t\t3000\t0.09720265\t0.00023495361\n",
      "\t\t4000\t0.07666735\t0.00024425238\n",
      "\t\t5000\t0.06584249\t8.078803e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.06584249\t8.078803e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.27850485\t0.00044805682\n",
      "\t\t2000\t0.14674544\t0.0005763376\n",
      "\t\t3000\t0.110850655\t0.000114651855\n",
      "\t\tFinal loss:\n",
      "\t\t3424\t0.10553507\t9.883731e-07\n",
      "k_2: 1\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.560851\t0.00047004747\n",
      "\t\t2000\t0.52315354\t7.063819e-06\n",
      "\t\t3000\t0.5208255\t2.4032897e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3768\t0.52013445\t9.167567e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.39739135\t0.00028962138\n",
      "\t\t2000\t0.31429887\t8.10659e-05\n",
      "\t\t3000\t0.28932586\t0.0001007298\n",
      "\t\t4000\t0.20229506\t0.00066662504\n",
      "\t\t5000\t0.13091193\t0.00013907584\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.13091193\t0.00013907584\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.2685838\t0.0005785485\n",
      "\t\t2000\t0.13245298\t0.00043631543\n",
      "\t\t3000\t0.10349746\t0.00017821066\n",
      "\t\t4000\t0.08531367\t0.00014730674\n",
      "\t\t5000\t0.0768667\t7.191584e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.0768667\t7.191584e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.32935047\t0.0004188752\n",
      "\t\t2000\t0.22152412\t0.0007681316\n",
      "\t\t3000\t0.1257315\t0.00022098301\n",
      "\t\t4000\t0.10292098\t0.00019722732\n",
      "\t\t5000\t0.08593899\t0.00017864887\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.08593899\t0.00017864887\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.28019023\t0.0005219776\n",
      "\t\t2000\t0.14978804\t0.0004676434\n",
      "\t\t3000\t0.11252554\t0.0001700706\n",
      "\t\t4000\t0.09698119\t0.00012090794\n",
      "\t\t5000\t0.07586743\t0.00023014015\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07586743\t0.00023014015\n",
      "k_2: 2\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5779601\t0.00011837848\n",
      "\t\t2000\t0.551701\t1.9770554e-05\n",
      "\t\t3000\t0.54015106\t2.5379419e-05\n",
      "\t\t4000\t0.52478325\t3.0551964e-05\n",
      "\t\t5000\t0.50983304\t2.642099e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.50983304\t2.642099e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.35721856\t0.00033635524\n",
      "\t\t2000\t0.28192964\t0.0002508887\n",
      "\t\t3000\t0.20135427\t0.0006562128\n",
      "\t\t4000\t0.13238342\t0.00016723713\n",
      "\t\t5000\t0.11883401\t0.00010187286\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.11883401\t0.00010187286\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.27380303\t0.00046020604\n",
      "\t\t2000\t0.13460204\t0.0005205973\n",
      "\t\t3000\t0.100591615\t0.00017965575\n",
      "\t\t4000\t0.08604158\t0.0001722034\n",
      "\t\t5000\t0.07328476\t8.518899e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07328476\t8.518899e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.2832294\t0.00038991054\n",
      "\t\t2000\t0.17908545\t0.0005318257\n",
      "\t\t3000\t0.109608695\t0.00028486733\n",
      "\t\t4000\t0.08871742\t0.00016365224\n",
      "\t\t5000\t0.07684694\t0.00014143516\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07684694\t0.00014143516\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.28016096\t0.00036803086\n",
      "\t\t2000\t0.12947233\t0.0006444419\n",
      "\t\t3000\t0.091839634\t0.0002447783\n",
      "\t\t4000\t0.07657739\t0.00012539726\n",
      "\t\t5000\t0.06870866\t0.000101507605\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.06870866\t0.000101507605\n",
      "k_2: 3\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.53932166\t5.470332e-05\n",
      "\t\t2000\t0.52040327\t1.7523624e-05\n",
      "\t\t3000\t0.5156389\t4.508137e-06\n",
      "\t\t4000\t0.5142737\t1.2749052e-06\n",
      "\t\tFinal loss:\n",
      "\t\t4298\t0.5140721\t9.275677e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.466138\t0.00014964837\n",
      "\t\t2000\t0.33801264\t0.0002263674\n",
      "\t\t3000\t0.2790569\t0.0003221015\n",
      "\t\t4000\t0.18276326\t0.000548902\n",
      "\t\t5000\t0.13551556\t0.00017392496\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.13551556\t0.00017392496\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.2866822\t0.00033732722\n",
      "\t\t2000\t0.16753423\t0.0004913518\n",
      "\t\t3000\t0.11680962\t0.0002372838\n",
      "\t\t4000\t0.09483313\t0.0001805887\n",
      "\t\t5000\t0.08112566\t0.00013305845\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.08112566\t0.00013305845\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.29331687\t0.00038361308\n",
      "\t\t2000\t0.14510944\t0.0006153451\n",
      "\t\t3000\t0.10717083\t0.00014492945\n",
      "\t\t4000\t0.08793158\t0.00019713149\n",
      "\t\t5000\t0.071086906\t0.00016305693\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.071086906\t0.00016305693\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.26715147\t0.0006857098\n",
      "\t\t2000\t0.12329905\t0.00058338343\n",
      "\t\t3000\t0.08890722\t0.00021255985\n",
      "\t\tFinal loss:\n",
      "\t\t4000\t0.07467247\t8.979921e-07\n",
      "k_2: 4\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6684203\t0.00079897005\n",
      "\t\t2000\t0.5339489\t3.259486e-05\n",
      "\t\t3000\t0.5201437\t1.5928124e-05\n",
      "\t\t4000\t0.51530725\t4.8580396e-06\n",
      "\t\t5000\t0.5138266\t1.5080169e-06\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.5138266\t1.5080169e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.38986635\t0.000512971\n",
      "\t\t2000\t0.28462663\t0.00017378296\n",
      "\t\t3000\t0.21070604\t0.00039573468\n",
      "\t\t4000\t0.15933105\t0.00016990291\n",
      "\t\t5000\t0.14470823\t4.6027184e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.14470823\t4.6027184e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.32201782\t0.00047408708\n",
      "\t\t2000\t0.22018912\t0.0005391416\n",
      "\t\t3000\t0.1140101\t0.0002597648\n",
      "\t\t4000\t0.09471291\t0.00015683318\n",
      "\t\t5000\t0.08307725\t0.000109490415\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.08307725\t0.000109490415\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.28543037\t0.00044178026\n",
      "\t\t2000\t0.159345\t0.00056880905\n",
      "\t\t3000\t0.109976925\t0.00021457569\n",
      "\t\t4000\t0.08940331\t0.00020704893\n",
      "\t\t5000\t0.07580748\t0.0001657758\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07580748\t0.0001657758\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.266513\t0.0005242874\n",
      "\t\t2000\t0.1385374\t0.0006503182\n",
      "\t\t3000\t0.09723823\t0.00015322038\n",
      "\t\t4000\t0.080319375\t0.00018947672\n",
      "\t\t5000\t0.06691379\t0.00014940396\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.06691379\t0.00014940396\n",
      "k_2: 5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.30728027\t0.00046319127\n",
      "\t\t2000\t0.15616514\t0.000689882\n",
      "\t\t3000\t0.111257024\t0.00023232249\n",
      "\t\t4000\t0.09323715\t0.00011194138\n",
      "\t\t5000\t0.08434219\t0.00010034136\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.08434219\t0.00010034136\n",
      "k_1: 1\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5855439\t0.00036571256\n",
      "\t\t2000\t0.51516277\t1.5272248e-05\n",
      "\t\t3000\t0.5114347\t4.4286526e-06\n",
      "\t\t4000\t0.50993335\t1.7533039e-06\n",
      "\t\tFinal loss:\n",
      "\t\t4491\t0.50955874\t9.357836e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.3814706\t0.00044058604\n",
      "\t\t2000\t0.2924805\t0.00014915214\n",
      "\t\t3000\t0.21637194\t0.0005826303\n",
      "\t\t4000\t0.14668347\t0.00035349999\n",
      "\t\t5000\t0.11843885\t0.00017541563\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.11843885\t0.00017541563\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.29416397\t0.0003806866\n",
      "\t\t2000\t0.161507\t0.0006228501\n",
      "\t\t3000\t0.11283999\t0.00019593223\n",
      "\t\t4000\t0.09555389\t0.0001888918\n",
      "\t\t5000\t0.07986384\t0.00014635222\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07986384\t0.00014635222\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.24753173\t0.00057270605\n",
      "\t\t2000\t0.1121913\t0.00033731342\n",
      "\t\t3000\t0.08827348\t0.00019214959\n",
      "\t\t4000\t0.07515023\t0.0001361041\n",
      "\t\tFinal loss:\n",
      "\t\t4027\t0.0748876\t5.9694065e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.26181972\t0.000662493\n",
      "\t\t2000\t0.13328643\t0.00038477252\n",
      "\t\t3000\t0.10521178\t0.00023703268\n",
      "\t\t4000\t0.08073283\t0.00024735992\n",
      "\t\t5000\t0.067745335\t0.00036928387\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.067745335\t0.00036928387\n",
      "k_2: 1\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5892005\t0.0001785189\n",
      "\t\t2000\t0.5131393\t1.0802471e-05\n",
      "\t\t3000\t0.51077974\t3.5007909e-06\n",
      "\t\t4000\t0.5095761\t1.5205957e-06\n",
      "\t\tFinal loss:\n",
      "\t\t4311\t0.50936455\t9.3614034e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.3396214\t0.0005535815\n",
      "\t\t2000\t0.24479727\t0.00041770784\n",
      "\t\t3000\t0.1591605\t0.00031980916\n",
      "\t\t4000\t0.12636042\t0.0001486824\n",
      "\t\t5000\t0.11397966\t6.3075786e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.11397966\t6.3075786e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.26598075\t0.00038977127\n",
      "\t\t2000\t0.16268618\t0.00074950524\n",
      "\t\t3000\t0.10956871\t0.00016677413\n",
      "\t\t4000\t0.09390118\t0.00016128218\n",
      "\t\t5000\t0.076327294\t0.00018221136\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.076327294\t0.00018221136\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.32663408\t0.00064766296\n",
      "\t\t2000\t0.20553842\t0.00057899754\n",
      "\t\t3000\t0.1274781\t0.0002922613\n",
      "\t\t4000\t0.09816928\t0.00025251554\n",
      "\t\t5000\t0.08098925\t0.00016547105\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.08098925\t0.00016547105\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.28988886\t0.0003451035\n",
      "\t\t2000\t0.14312492\t0.00065111474\n",
      "\t\t3000\t0.097973995\t0.00026122757\n",
      "\t\t4000\t0.07951823\t0.0001984886\n",
      "\t\t5000\t0.068416774\t0.00012837652\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.068416774\t0.00012837652\n",
      "k_2: 2\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.52260554\t4.9952647e-05\n",
      "\t\t2000\t0.5141241\t8.926865e-06\n",
      "\t\t3000\t0.5113219\t2.9142343e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3984\t0.5103435\t9.3434465e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.46976507\t0.00019478909\n",
      "\t\t2000\t0.31709355\t0.00031447186\n",
      "\t\t3000\t0.23110235\t0.00036604007\n",
      "\t\t4000\t0.16044503\t0.0002685193\n",
      "\t\t5000\t0.13824564\t7.296685e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.13824564\t7.296685e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.24372852\t0.00079154264\n",
      "\t\t2000\t0.117663644\t0.0003311858\n",
      "\t\t3000\t0.09065558\t0.00018800523\n",
      "\t\t4000\t0.07887846\t0.000112296126\n",
      "\t\t5000\t0.072486915\t6.6703135e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.072486915\t6.6703135e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.2734971\t0.00050927297\n",
      "\t\t2000\t0.15479776\t0.00043808942\n",
      "\t\t3000\t0.110330515\t0.00019444757\n",
      "\t\t4000\t0.09006765\t0.00020113957\n",
      "\t\tFinal loss:\n",
      "\t\t4740\t0.077821\t5.744395e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.3138767\t0.00036798237\n",
      "\t\t2000\t0.18175448\t0.00059993484\n",
      "\t\t3000\t0.11088309\t0.00022343438\n",
      "\t\t4000\t0.09093506\t0.00019381587\n",
      "\t\t5000\t0.07708254\t0.00014109958\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07708254\t0.00014109958\n",
      "k_2: 3\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6208465\t0.0006639166\n",
      "\t\t2000\t0.5239419\t8.873352e-06\n",
      "\t\t3000\t0.52096957\t4.5764186e-06\n",
      "\t\t4000\t0.51901305\t2.871049e-06\n",
      "\t\t5000\t0.51788294\t1.4962053e-06\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.51788294\t1.4962053e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.38003984\t0.00040259754\n",
      "\t\t2000\t0.2939098\t0.00017903956\n",
      "\t\t3000\t0.23439318\t0.0003494042\n",
      "\t\t4000\t0.16169904\t0.000260819\n",
      "\t\t5000\t0.13475038\t0.00015412956\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.13475038\t0.00015412956\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.3413223\t0.0008416994\n",
      "\t\t2000\t0.22394595\t0.0004221454\n",
      "\t\t3000\t0.12862618\t0.0003985919\n",
      "\t\t4000\t0.10312579\t0.00015422463\n",
      "\t\t5000\t0.090719536\t0.00012481841\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.090719536\t0.00012481841\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.26640195\t0.0004466083\n",
      "\t\t2000\t0.12476128\t0.0004422601\n",
      "\t\t3000\t0.09360733\t0.00024604404\n",
      "\t\t4000\t0.07434725\t0.00020279051\n",
      "\t\t5000\t0.065807484\t3.226604e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.065807484\t3.226604e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.28665516\t0.00035741046\n",
      "\t\t2000\t0.16894841\t0.0005977232\n",
      "\t\t3000\t0.10837723\t0.0002490761\n",
      "\t\t4000\t0.087312855\t0.00019238664\n",
      "\t\t5000\t0.073677845\t0.00012365906\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.073677845\t0.00012365906\n",
      "k_2: 4\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.52665365\t2.1050326e-05\n",
      "\t\t2000\t0.52325296\t6.492926e-06\n",
      "\t\t3000\t0.52017075\t3.8959324e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3798\t0.51920766\t9.183931e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.33234367\t0.00039781138\n",
      "\t\t2000\t0.2376403\t0.00065057655\n",
      "\t\t3000\t0.14874873\t0.00023285666\n",
      "\t\t4000\t0.12840414\t0.000102924794\n",
      "\t\t5000\t0.11911222\t6.473602e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.11911222\t6.473602e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.275329\t0.0005068595\n",
      "\t\t2000\t0.13557793\t0.00049225736\n",
      "\t\t3000\t0.10172056\t0.00021046348\n",
      "\t\t4000\t0.08651683\t0.00012786758\n",
      "\t\t5000\t0.077475235\t6.7216395e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.077475235\t6.7216395e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.29590085\t0.00041116014\n",
      "\t\t2000\t0.15563427\t0.00082635955\n",
      "\t\t3000\t0.112380475\t0.00018719\n",
      "\t\t4000\t0.089247525\t0.00022910617\n",
      "\t\t5000\t0.073684834\t0.00020097457\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.073684834\t0.00020097457\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.29741707\t0.00034508298\n",
      "\t\t2000\t0.17094643\t0.0008199324\n",
      "\t\t3000\t0.115027644\t0.00014591022\n",
      "\t\tFinal loss:\n",
      "\t\t3394\t0.108042665\t6.206369e-07\n",
      "k_2: 5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.24999912\t0.00086667767\n",
      "\t\t2000\t0.12662363\t0.00035080084\n",
      "\t\t3000\t0.09930623\t0.00016210559\n",
      "\t\t4000\t0.08508443\t0.000113211194\n",
      "\t\tFinal loss:\n",
      "\t\t4623\t0.07826994\t7.615272e-07\n",
      "k_1: 2\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5940663\t0.0005734772\n",
      "\t\t2000\t0.5191311\t6.8889226e-06\n",
      "\t\t3000\t0.5162925\t4.15609e-06\n",
      "\t\t4000\t0.51482403\t1.736648e-06\n",
      "\t\tFinal loss:\n",
      "\t\t4376\t0.5145372\t9.267293e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.35883123\t0.00037874826\n",
      "\t\t2000\t0.29670066\t0.00016821834\n",
      "\t\t3000\t0.24707645\t0.00019898314\n",
      "\t\t4000\t0.18980302\t0.00022966329\n",
      "\t\t5000\t0.15582824\t9.96319e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.15582824\t9.96319e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.3334462\t0.00045213097\n",
      "\t\t2000\t0.19654475\t0.0007329784\n",
      "\t\t3000\t0.12068894\t0.00025890602\n",
      "\t\t4000\t0.099991985\t0.00014527686\n",
      "\t\t5000\t0.08859018\t0.00010234123\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.08859018\t0.00010234123\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.25995997\t0.0006726103\n",
      "\t\t2000\t0.120410696\t0.00037279006\n",
      "\t\t3000\t0.09503216\t0.0002022327\n",
      "\t\t4000\t0.079923026\t0.0003068857\n",
      "\t\t5000\t0.06873182\t0.00013071421\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.06873182\t0.00013071421\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.28306934\t0.00043220943\n",
      "\t\t2000\t0.13887666\t0.0006847346\n",
      "\t\t3000\t0.09435017\t0.00023842447\n",
      "\t\t4000\t0.07700965\t0.00016531613\n",
      "\t\t5000\t0.06678972\t0.00016841637\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.06678972\t0.00016841637\n",
      "k_2: 1\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.553816\t0.00032244917\n",
      "\t\t2000\t0.5151995\t5.206129e-06\n",
      "\t\t3000\t0.5131713\t3.2521784e-06\n",
      "\t\t4000\t0.51171166\t2.329613e-06\n",
      "\t\t5000\t0.5108325\t1.4001747e-06\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.5108325\t1.4001747e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.4837044\t0.00015992094\n",
      "\t\t2000\t0.35111016\t0.00025712108\n",
      "\t\t3000\t0.27077487\t0.00030962168\n",
      "\t\t4000\t0.18269569\t0.00043209575\n",
      "\t\t5000\t0.14318095\t0.00015545974\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.14318095\t0.00015545974\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.29544175\t0.00035696567\n",
      "\t\t2000\t0.1665509\t0.0006328616\n",
      "\t\t3000\t0.115873545\t0.00018231939\n",
      "\t\t4000\t0.104162976\t8.41815e-05\n",
      "\t\t5000\t0.09416355\t0.00011827613\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.09416355\t0.00011827613\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.26848173\t0.00048196534\n",
      "\t\t2000\t0.14605246\t0.0005920128\n",
      "\t\t3000\t0.100178316\t0.00031814163\n",
      "\t\t4000\t0.079300284\t0.00013743584\n",
      "\t\t5000\t0.07020544\t0.00013826227\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07020544\t0.00013826227\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.27833915\t0.00038488265\n",
      "\t\t2000\t0.1397941\t0.0004924332\n",
      "\t\t3000\t0.0988328\t0.00025232765\n",
      "\t\t4000\t0.07960501\t0.00017779767\n",
      "\t\tFinal loss:\n",
      "\t\t4577\t0.07225037\t5.156082e-07\n",
      "k_2: 2\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5220174\t2.0323865e-05\n",
      "\t\t2000\t0.5156116\t6.4735523e-06\n",
      "\t\t3000\t0.5137094\t1.972471e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3565\t0.5132782\t9.290025e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.34426916\t0.00040522864\n",
      "\t\t2000\t0.21775232\t0.00048754332\n",
      "\t\t3000\t0.14670075\t0.00025295987\n",
      "\t\t4000\t0.11539637\t0.00015377047\n",
      "\t\t5000\t0.103803426\t6.4163505e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.103803426\t6.4163505e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.28997484\t0.00036554172\n",
      "\t\t2000\t0.16639785\t0.00058836455\n",
      "\t\t3000\t0.11053448\t0.0001699666\n",
      "\t\t4000\t0.09870711\t6.3023246e-05\n",
      "\t\t5000\t0.08995418\t0.0001103954\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.08995418\t0.0001103954\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.33288097\t0.00037417846\n",
      "\t\t2000\t0.20618363\t0.00056022225\n",
      "\t\t3000\t0.120249495\t0.0002778724\n",
      "\t\t4000\t0.10111395\t0.00013467802\n",
      "\t\t5000\t0.08732723\t0.00016548944\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.08732723\t0.00016548944\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.25632828\t0.00051630416\n",
      "\t\t2000\t0.12596667\t0.00052613346\n",
      "\t\t3000\t0.09191829\t0.0002530756\n",
      "\t\t4000\t0.07340892\t0.00016185708\n",
      "\t\t5000\t0.0634316\t0.00010006463\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.0634316\t0.00010006463\n",
      "k_2: 3\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6341868\t0.00010346781\n",
      "\t\t2000\t0.5811526\t5.466299e-05\n",
      "\t\t3000\t0.52304286\t4.1820644e-05\n",
      "\t\t4000\t0.5165387\t4.038718e-06\n",
      "\t\tFinal loss:\n",
      "\t\t4877\t0.5155403\t9.2492616e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.39856756\t0.0004817583\n",
      "\t\t2000\t0.29971656\t0.0001143372\n",
      "\t\t3000\t0.2674475\t0.00010529255\n",
      "\t\t4000\t0.23290715\t0.0003272733\n",
      "\t\t5000\t0.15251158\t0.0003147068\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.15251158\t0.0003147068\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.2822788\t0.00035166088\n",
      "\t\t2000\t0.16743223\t0.0007586673\n",
      "\t\t3000\t0.11213164\t0.00021350845\n",
      "\t\t4000\t0.092572615\t0.00015788396\n",
      "\t\t5000\t0.07902869\t0.00015345926\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07902869\t0.00015345926\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.28893542\t0.0003881912\n",
      "\t\t2000\t0.16204597\t0.0008081946\n",
      "\t\t3000\t0.105138555\t0.0002276355\n",
      "\t\t4000\t0.08802741\t0.00015715053\n",
      "\t\t5000\t0.07605651\t0.00011185908\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07605651\t0.00011185908\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.22449686\t0.0008886455\n",
      "\t\t2000\t0.114105135\t0.00025034652\n",
      "\t\t3000\t0.08835799\t0.00023866046\n",
      "\t\tFinal loss:\n",
      "\t\t3904\t0.0740821\t2.0114392e-07\n",
      "k_2: 4\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.523318\t0.000121513935\n",
      "\t\t2000\t0.5055634\t1.6387481e-05\n",
      "\t\t3000\t0.49515125\t2.50979e-05\n",
      "\t\t4000\t0.48193222\t2.7084854e-05\n",
      "\t\t5000\t0.47009066\t2.2125052e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.47009066\t2.2125052e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.46949828\t0.0001576519\n",
      "\t\t2000\t0.3490244\t0.00024303915\n",
      "\t\t3000\t0.29056755\t0.00015813162\n",
      "\t\t4000\t0.2394439\t0.000313615\n",
      "\t\t5000\t0.16117656\t0.00030647824\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.16117656\t0.00030647824\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.32507282\t0.00057577854\n",
      "\t\t2000\t0.20546125\t0.00053973275\n",
      "\t\t3000\t0.13476102\t0.00021877949\n",
      "\t\t4000\t0.114125\t0.00013016013\n",
      "\t\t5000\t0.09943855\t0.00015402513\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.09943855\t0.00015402513\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.29471233\t0.0002672989\n",
      "\t\t2000\t0.19780329\t0.00072440656\n",
      "\t\t3000\t0.11603209\t0.00026813903\n",
      "\t\t4000\t0.09332697\t0.00016251375\n",
      "\t\tFinal loss:\n",
      "\t\t4352\t0.088429786\t8.4254204e-08\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.29229409\t0.00035357437\n",
      "\t\t2000\t0.18606074\t0.00058973755\n",
      "\t\t3000\t0.11498958\t0.00034639577\n",
      "\t\t4000\t0.08939262\t0.00021965367\n",
      "\t\t5000\t0.07686926\t0.000111936264\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07686926\t0.000111936264\n",
      "k_2: 5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.32865447\t0.00038678106\n",
      "\t\t2000\t0.1639087\t0.0007372017\n",
      "\t\t3000\t0.11087348\t0.00028719296\n",
      "\t\t4000\t0.088021696\t0.00018483012\n",
      "\t\tFinal loss:\n",
      "\t\t4763\t0.07876345\t5.675667e-07\n",
      "k_1: 3\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5104997\t1.1675731e-06\n",
      "\t\tFinal loss:\n",
      "\t\t1519\t0.51017183\t9.3465906e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.4325537\t0.0005018118\n",
      "\t\t2000\t0.27784806\t0.0003639121\n",
      "\t\t3000\t0.17590606\t0.00027049344\n",
      "\t\t4000\t0.14332902\t0.00013170595\n",
      "\t\t5000\t0.13202201\t4.491975e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.13202201\t4.491975e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.30770138\t0.0003338435\n",
      "\t\t2000\t0.20279151\t0.00063608063\n",
      "\t\t3000\t0.11477662\t0.00026069055\n",
      "\t\t4000\t0.09432208\t0.00017138076\n",
      "\t\t5000\t0.08280837\t0.00010157006\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.08280837\t0.00010157006\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.3044516\t0.00026148977\n",
      "\t\t2000\t0.17364569\t0.00061696215\n",
      "\t\t3000\t0.106417805\t0.0002796219\n",
      "\t\t4000\t0.08515291\t0.0001811724\n",
      "\t\t5000\t0.07289332\t0.0001355149\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07289332\t0.0001355149\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.27588344\t0.00044680794\n",
      "\t\t2000\t0.13790177\t0.00066367356\n",
      "\t\t3000\t0.0992482\t0.00022733588\n",
      "\t\t4000\t0.08302611\t0.00015315897\n",
      "\t\t5000\t0.07097968\t0.00014598889\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07097968\t0.00014598889\n",
      "k_2: 1\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6487356\t0.00041493337\n",
      "\t\t2000\t0.5289277\t1.4424059e-05\n",
      "\t\t3000\t0.5235307\t7.627978e-06\n",
      "\t\t4000\t0.52073437\t3.6627919e-06\n",
      "\t\t5000\t0.5194513\t1.7211779e-06\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.5194513\t1.7211779e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.47061962\t0.0004860418\n",
      "\t\t2000\t0.289841\t0.00024928362\n",
      "\t\t3000\t0.21708861\t0.00023167804\n",
      "\t\t4000\t0.15113835\t0.0002645532\n",
      "\t\t5000\t0.13148075\t6.4142594e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.13148075\t6.4142594e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.27896345\t0.00044828118\n",
      "\t\t2000\t0.16058445\t0.00063254277\n",
      "\t\t3000\t0.110888\t0.00019273137\n",
      "\t\t4000\t0.09320101\t0.00015817818\n",
      "\t\t5000\t0.08170494\t0.0001125144\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.08170494\t0.0001125144\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.2813352\t0.00036755385\n",
      "\t\t2000\t0.14613685\t0.0006397404\n",
      "\t\t3000\t0.10075635\t0.0002226773\n",
      "\t\t4000\t0.085222416\t0.00014125905\n",
      "\t\t5000\t0.07503673\t0.0001137762\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07503673\t0.0001137762\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.2811409\t0.00049966946\n",
      "\t\t2000\t0.1387598\t0.0006326527\n",
      "\t\t3000\t0.09781697\t0.00024276652\n",
      "\t\t4000\t0.08019108\t0.00016005889\n",
      "\t\tFinal loss:\n",
      "\t\t4132\t0.07858303\t4.7405763e-07\n",
      "k_2: 2\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.54970294\t9.0639805e-05\n",
      "\t\t2000\t0.53084797\t2.4925972e-05\n",
      "\t\t3000\t0.52073354\t1.3506434e-05\n",
      "\t\t4000\t0.5155565\t7.167908e-06\n",
      "\t\t5000\t0.512884\t3.7188554e-06\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.512884\t3.7188554e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.4109154\t0.00030198233\n",
      "\t\t2000\t0.30406818\t0.0001919686\n",
      "\t\t3000\t0.26590097\t0.0002005839\n",
      "\t\t4000\t0.18280244\t0.0003486001\n",
      "\t\t5000\t0.14737691\t0.000114543596\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.14737691\t0.000114543596\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.30843297\t0.0003697436\n",
      "\t\t2000\t0.19224544\t0.0005998087\n",
      "\t\t3000\t0.12751843\t0.00021788702\n",
      "\t\t4000\t0.11452747\t9.581678e-05\n",
      "\t\t5000\t0.09554688\t0.00020924989\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.09554688\t0.00020924989\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.2602898\t0.00062224566\n",
      "\t\t2000\t0.1253715\t0.00040917273\n",
      "\t\t3000\t0.098304205\t0.0001953512\n",
      "\t\t4000\t0.08163856\t0.00015174736\n",
      "\t\t5000\t0.07257096\t5.5237437e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07257096\t5.5237437e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.25162417\t0.0007114353\n",
      "\t\t2000\t0.11535765\t0.00036510496\n",
      "\t\t3000\t0.090102896\t0.00017494078\n",
      "\t\t4000\t0.07670651\t0.0001584927\n",
      "\t\tFinal loss:\n",
      "\t\t4068\t0.075916976\t2.9442342e-07\n",
      "k_2: 3\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.53504896\t0.00015493389\n",
      "\t\t2000\t0.5175252\t5.8737605e-06\n",
      "\t\t3000\t0.5149355\t4.2827937e-06\n",
      "\t\t4000\t0.5132012\t2.4389938e-06\n",
      "\t\tFinal loss:\n",
      "\t\t4840\t0.51244706\t9.305092e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.44335592\t0.0003985221\n",
      "\t\t2000\t0.29647943\t0.0001891442\n",
      "\t\t3000\t0.23315164\t0.0004528023\n",
      "\t\t4000\t0.14036077\t0.00016930178\n",
      "\t\t5000\t0.1297745\t4.1219937e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.1297745\t4.1219937e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.29186848\t0.00036531367\n",
      "\t\t2000\t0.15721281\t0.00071661716\n",
      "\t\t3000\t0.106716074\t0.00019754267\n",
      "\t\t4000\t0.09110818\t0.00013990137\n",
      "\t\t5000\t0.07977133\t0.00011748242\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07977133\t0.00011748242\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.2966628\t0.00042596375\n",
      "\t\t2000\t0.16907078\t0.0007768405\n",
      "\t\t3000\t0.11027734\t0.0002492424\n",
      "\t\t4000\t0.08899677\t0.0001849813\n",
      "\t\t5000\t0.07369281\t0.00018154841\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07369281\t0.00018154841\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.25524572\t0.00061855844\n",
      "\t\t2000\t0.11847822\t0.00043146088\n",
      "\t\tFinal loss:\n",
      "\t\t2882\t0.09288736\t8.823194e-07\n",
      "k_2: 4\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5880758\t8.3509854e-05\n",
      "\t\t2000\t0.55858785\t2.9876772e-05\n",
      "\t\t3000\t0.5458942\t2.391142e-05\n",
      "\t\t4000\t0.5306302\t3.145086e-05\n",
      "\t\t5000\t0.51472574\t2.8022534e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.51472574\t2.8022534e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.35954207\t0.0003985404\n",
      "\t\t2000\t0.28974703\t0.00014274423\n",
      "\t\t3000\t0.24014138\t0.00027214637\n",
      "\t\t4000\t0.18212566\t0.0001703979\n",
      "\t\t5000\t0.15975975\t0.00010464059\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.15975975\t0.00010464059\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.28110048\t0.00045536124\n",
      "\t\t2000\t0.16680771\t0.0005285622\n",
      "\t\t3000\t0.113933295\t0.00019895507\n",
      "\t\t4000\t0.09556212\t0.00017819814\n",
      "\t\t5000\t0.08147268\t0.00014044566\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.08147268\t0.00014044566\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.28901267\t0.0005539506\n",
      "\t\t2000\t0.14161721\t0.0006804244\n",
      "\t\t3000\t0.10122117\t0.00022334718\n",
      "\t\t4000\t0.08071712\t0.0001668593\n",
      "\t\tFinal loss:\n",
      "\t\t4555\t0.07468309\t2.9928793e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.26718876\t0.0005689779\n",
      "\t\t2000\t0.12510955\t0.00048083338\n",
      "\t\t3000\t0.097034626\t0.00017848791\n",
      "\t\t4000\t0.08053362\t0.00020154989\n",
      "\t\t5000\t0.066632636\t0.0001888212\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.066632636\t0.0001888212\n",
      "k_2: 5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.30732942\t0.000489856\n",
      "\t\t2000\t0.16500658\t0.0004866955\n",
      "\t\t3000\t0.12529062\t0.00017349282\n",
      "\t\t4000\t0.105537124\t0.00016686293\n",
      "\t\t5000\t0.090993404\t0.0001945101\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.090993404\t0.0001945101\n",
      "k_1: 4\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.57066375\t0.00029362133\n",
      "\t\t2000\t0.5158811\t7.2789353e-06\n",
      "\t\t3000\t0.51382643\t3.0160304e-06\n",
      "\t\t4000\t0.51266843\t1.6276869e-06\n",
      "\t\tFinal loss:\n",
      "\t\t4515\t0.5122986\t9.307789e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.46580794\t0.00023929134\n",
      "\t\t2000\t0.320205\t0.00024909337\n",
      "\t\t3000\t0.26874965\t0.00026562787\n",
      "\t\t4000\t0.20396523\t0.00027359798\n",
      "\t\t5000\t0.14599863\t0.00029538714\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.14599863\t0.00029538714\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.30139148\t0.0003123709\n",
      "\t\t2000\t0.20295\t0.00059847813\n",
      "\t\t3000\t0.119782805\t0.00030307457\n",
      "\t\t4000\t0.09782287\t0.00020483919\n",
      "\t\t5000\t0.08371545\t0.00012048996\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.08371545\t0.00012048996\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.27845153\t0.00039274828\n",
      "\t\t2000\t0.16352169\t0.0005831428\n",
      "\t\t3000\t0.111271255\t0.00020331229\n",
      "\t\t4000\t0.092557415\t0.0002168115\n",
      "\t\t5000\t0.07103077\t0.00014504499\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07103077\t0.00014504499\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.29200697\t0.0003962452\n",
      "\t\t2000\t0.17423987\t0.0009201278\n",
      "\t\t3000\t0.10485004\t0.00023437\n",
      "\t\t4000\t0.084984355\t0.0001919605\n",
      "\t\tFinal loss:\n",
      "\t\t4690\t0.076121375\t5.872655e-07\n",
      "k_2: 1\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5211201\t9.1265276e-05\n",
      "\t\t2000\t0.49166894\t4.2731477e-05\n",
      "\t\t3000\t0.4742063\t3.0354056e-05\n",
      "\t\t4000\t0.4625411\t2.0037865e-05\n",
      "\t\t5000\t0.45501482\t1.3295811e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.45501482\t1.3295811e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.347732\t0.000366511\n",
      "\t\t2000\t0.2721748\t0.00027957713\n",
      "\t\t3000\t0.18928927\t0.00048807196\n",
      "\t\t4000\t0.13726348\t0.00015847076\n",
      "\t\t5000\t0.12232981\t0.000105051266\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.12232981\t0.000105051266\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.29122752\t0.00047133036\n",
      "\t\t2000\t0.15146478\t0.0006228515\n",
      "\t\t3000\t0.11237667\t0.00019130539\n",
      "\t\t4000\t0.09509997\t0.00015658657\n",
      "\t\t5000\t0.08188732\t0.00013427695\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.08188732\t0.00013427695\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.2899943\t0.0004060795\n",
      "\t\t2000\t0.16356133\t0.00066443835\n",
      "\t\t3000\t0.10617788\t0.00022807306\n",
      "\t\t4000\t0.08614927\t0.00018979756\n",
      "\t\t5000\t0.07405961\t0.00011829452\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07405961\t0.00011829452\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.26569486\t0.0004850012\n",
      "\t\t2000\t0.121516064\t0.0003875353\n",
      "\t\t3000\t0.096337795\t0.000197869\n",
      "\t\t4000\t0.0799802\t0.00016727895\n",
      "\t\tFinal loss:\n",
      "\t\t4609\t0.072771214\t3.0715097e-07\n",
      "k_2: 2\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5260687\t5.778069e-05\n",
      "\t\t2000\t0.51686275\t8.64893e-06\n",
      "\t\t3000\t0.50975394\t2.1163569e-05\n",
      "\t\t4000\t0.49526176\t3.429851e-05\n",
      "\t\t5000\t0.47914255\t2.9543786e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.47914255\t2.9543786e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.41787744\t0.0002671584\n",
      "\t\t2000\t0.2689304\t0.00027010124\n",
      "\t\t3000\t0.15583292\t0.00043862002\n",
      "\t\t4000\t0.12508616\t0.0001698465\n",
      "\t\t5000\t0.11235269\t3.3620177e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.11235269\t3.3620177e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.269477\t0.00037532297\n",
      "\t\t2000\t0.15225893\t0.0006012282\n",
      "\t\t3000\t0.10813668\t0.0002861273\n",
      "\t\t4000\t0.08603946\t0.00019705121\n",
      "\t\t5000\t0.073431\t0.000103482256\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.073431\t0.000103482256\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.31260175\t0.00061073306\n",
      "\t\t2000\t0.19737779\t0.00053429895\n",
      "\t\t3000\t0.12755588\t0.00028297634\n",
      "\t\t4000\t0.1041106\t0.00011291539\n",
      "\t\t5000\t0.08402828\t0.00021780869\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.08402828\t0.00021780869\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.25979027\t0.00044857102\n",
      "\t\t2000\t0.12963293\t0.00059554016\n",
      "\t\t3000\t0.09690887\t0.00021637697\n",
      "\t\t4000\t0.07660658\t0.00020079684\n",
      "\t\tFinal loss:\n",
      "\t\t4497\t0.07012029\t0.0\n",
      "k_2: 3\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.56734127\t0.00038909435\n",
      "\t\t2000\t0.5173224\t2.4195635e-06\n",
      "\t\t3000\t0.5162788\t1.3854041e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3327\t0.5160564\t9.2400114e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.35873535\t0.00051555334\n",
      "\t\t2000\t0.22747344\t0.0005173705\n",
      "\t\t3000\t0.1406087\t0.0002489818\n",
      "\t\t4000\t0.119568795\t8.940984e-05\n",
      "\t\t5000\t0.111985534\t4.4574208e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.111985534\t4.4574208e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.32716405\t0.000499577\n",
      "\t\t2000\t0.22110718\t0.0004380672\n",
      "\t\t3000\t0.13496052\t0.00042170353\n",
      "\t\t4000\t0.10441172\t0.00018000307\n",
      "\t\t5000\t0.08988774\t0.00012489605\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.08988774\t0.00012489605\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.2751591\t0.00057338603\n",
      "\t\t2000\t0.14860578\t0.00054118165\n",
      "\t\t3000\t0.107787415\t0.00024746792\n",
      "\t\t4000\t0.08737054\t0.0001572236\n",
      "\t\t5000\t0.07539717\t0.00013022487\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07539717\t0.00013022487\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.26209572\t0.00039952315\n",
      "\t\t2000\t0.123210564\t0.00042722153\n",
      "\t\t3000\t0.09746718\t0.00026716964\n",
      "\t\t4000\t0.07433752\t0.00020081333\n",
      "\t\t5000\t0.063117534\t8.510173e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.063117534\t8.510173e-05\n",
      "k_2: 4\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.52452564\t7.453922e-05\n",
      "\t\t2000\t0.51689106\t2.9981484e-06\n",
      "\t\t3000\t0.5157373\t1.7335727e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3931\t0.5149924\t9.259102e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.33775377\t0.00032134348\n",
      "\t\t2000\t0.25391063\t0.00037627446\n",
      "\t\t3000\t0.16015378\t0.00033660867\n",
      "\t\t4000\t0.12929925\t0.00013228437\n",
      "\t\t5000\t0.11509916\t7.728385e-05\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.11509916\t7.728385e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.29901108\t0.00024642225\n",
      "\t\t2000\t0.17641146\t0.00066719134\n",
      "\t\t3000\t0.11170838\t0.00018378234\n",
      "\t\t4000\t0.09595553\t0.00016706667\n",
      "\t\t5000\t0.0826677\t0.000104265906\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.0826677\t0.000104265906\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.27523708\t0.0004437458\n",
      "\t\t2000\t0.15693898\t0.0006011388\n",
      "\t\t3000\t0.11300777\t0.00012445998\n",
      "\t\t4000\t0.098523594\t0.0002300657\n",
      "\t\t5000\t0.07912078\t0.0002468454\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.07912078\t0.0002468454\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.26179445\t0.0006933654\n",
      "\t\t2000\t0.12023432\t0.00035364548\n",
      "\t\t3000\t0.094161876\t0.00018345776\n",
      "\t\t4000\t0.07928191\t0.00016180014\n",
      "\t\t5000\t0.06806183\t0.00012455888\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.06806183\t0.00012455888\n",
      "k_2: 5\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.3010983\t0.00045608377\n",
      "\t\t2000\t0.13656268\t0.00040759996\n",
      "\t\t3000\t0.10795929\t0.00017912532\n",
      "\t\tFinal loss:\n",
      "\t\t3098\t0.10612788\t4.914269e-07\n",
      "k_1: 5\n"
     ]
    }
   ],
   "source": [
    "# %% Define variables for double cross validation\n",
    "\n",
    "from matplotlib.pyplot import figure, plot, subplot, title, xlabel, ylabel, show, clim\n",
    "from scipy.io import loadmat\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn import model_selection\n",
    "from toolbox_02450 import feature_selector_lr, bmplot\n",
    "import numpy as np\n",
    "from toolbox_02450 import train_neural_net, draw_neural_net\n",
    "import torch\n",
    "from toolbox_02450 import rlr_validate\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "## Crossvalidation\n",
    "# Create crossvalidation partition for evaluation\n",
    "K1 = 5\n",
    "K2 = 5\n",
    "CV1 = model_selection.KFold(n_splits=K1,shuffle=True)\n",
    "size_val = np.empty(K2)\n",
    "size_par = np.empty(K1)\n",
    "size_test = np.empty(K1)\n",
    "  \n",
    "#ANN\n",
    "h = 0\n",
    "h_values = [1, 10, 50, 75, 100]\n",
    "h_number = len(h_values)\n",
    "n_replicates = 1        # number of networks trained in each k-fold\n",
    "max_iter = 5000\n",
    "loss_fn = torch.nn.MSELoss() # notice how this is now a mean-squared-error loss\n",
    "Eval_ANN = np.empty((K2,h_number))\n",
    "Egen_ANN_temp = np.empty((h_number))\n",
    "Etest_ANN = np.empty(K1)\n",
    "optimal_ANN = np.empty(K1) \n",
    "\n",
    "\n",
    "class Squeeze(torch.nn.Module):\n",
    "    def forward(self, input):\n",
    "        return torch.squeeze(input)\n",
    "\n",
    "#baseline \n",
    "Error_val_nofeatures = np.empty((K2,1))\n",
    "Etest_nofeatures = np.empty((K1,1))\n",
    "\n",
    "#Linear regression\n",
    "lambdas = np.power(10.,range(-1,3))\n",
    "opt_lambda = np.empty((K1,1)) \n",
    "mu = np.empty((K1, M-1))\n",
    "sigma = np.empty((K1, M-1))\n",
    "w_rlr = np.empty((M,K1))\n",
    "w = np.empty((M,K2,len(lambdas)))\n",
    "Error_test_rlr = np.empty((K1,1))\n",
    "Eval_rlr = np.empty((K2,len(lambdas))) \n",
    "Egen_rlr_temp = np.empty((len(lambdas)))\n",
    "\n",
    " # %% Double crosss validation\n",
    " \n",
    "k_1 = 0\n",
    "for par_index, test_index in CV1.split(X):\n",
    "    \n",
    "    \n",
    "    X_par = X[par_index,:]\n",
    "    y_par = y[par_index]\n",
    "    X_test = X[test_index,:]\n",
    "    y_test = y[test_index]      \n",
    "    size_par[k_1] = len(par_index)\n",
    "    size_test[k_1] = len(test_index)\n",
    "    X_par_rlr = X[par_index,:]\n",
    "    X_test_rlr = X[test_index,:]\n",
    "    \n",
    "    X_test_ANN = torch.from_numpy(X_test).float()\n",
    "    y_test_ANN = torch.from_numpy(y_test).float()\n",
    "    X_par_ANN = torch.from_numpy(X_par).float()\n",
    "    y_par_ANN = torch.from_numpy(y_par).float()\n",
    "    \n",
    "    CV2 = model_selection.KFold(n_splits=K2,shuffle=True)\n",
    "    \n",
    "    k_2 = 0\n",
    "    for train_index, val_index in CV2.split(X_par):\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train = X[train_index,:]\n",
    "        y_train = y[train_index]\n",
    "        X_val = X[val_index,:]\n",
    "        y_val = y[val_index]      \n",
    "        size_val[k_2] = len(val_index) \n",
    "        X_train_rlr = X[train_index,:]\n",
    "        X_val_rlr = X[val_index,:]\n",
    "        \n",
    "        X_train_ANN = torch.from_numpy(X_train).float()\n",
    "        y_train_ANN = torch.from_numpy(y_train).float()\n",
    "        X_val_ANN = torch.from_numpy(X_val).float()\n",
    "        y_val_ANN = torch.from_numpy(y_val).float()\n",
    "    \n",
    "    \n",
    "        #ANN\n",
    "        \n",
    "        \n",
    "        h_index = 0\n",
    "        for h in h_values:\n",
    "            # Define the model\n",
    "            model = lambda: torch.nn.Sequential(\n",
    "                torch.nn.Linear(M, h), #M features to n_hidden_units\n",
    "                torch.nn.Tanh(),   # 1st transfer function,\n",
    "                torch.nn.Linear(h, 1), # n_hidden_units to 1 output neuron\n",
    "                Squeeze() # remove the extra dimension\n",
    "                ) \n",
    "            \n",
    "            \n",
    "            #Train the model\n",
    "            net, final_loss, learning_curve = train_neural_net(model,\n",
    "                                                                loss_fn,\n",
    "                                                                X=X_train_ANN,\n",
    "                                                                y=y_train_ANN,\n",
    "                                                                n_replicates=n_replicates,\n",
    "                                                                max_iter=max_iter)\n",
    "            # Test model\n",
    "            y_test_est_ANN = net(X_val_ANN)\n",
    "            \n",
    "            # Determine errors and errors\n",
    "            se = (y_test_est_ANN.float()-y_val_ANN.float())**2 # squared error\n",
    "            Eval_ANN[k_2, h_index] = (sum(se).type(torch.float)/len(y_val)).data.numpy() #mean\n",
    "            h_index = h_index + 1\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        #Linear regression\n",
    "        \n",
    "        # Standardize the training and set set based on training set moments\n",
    "        mu_rlr = np.mean(X_train[:, 1:], 0)\n",
    "        sigma_rlr = np.std(X_train[:, 1:], 0)\n",
    "        X_train_rlr[:, 1:] = (X_train[:, 1:] - mu_rlr) / sigma_rlr\n",
    "        X_val_rlr[:, 1:] = (X_val[:, 1:] - mu_rlr) / sigma_rlr\n",
    "        \n",
    "        Xty = X_train_rlr.T @ y_train\n",
    "        XtX = X_train_rlr.T @ X_train_rlr\n",
    "        \n",
    "        for l in range(0,len(lambdas)):\n",
    "            # Compute parameters for current value of lambda and current CV fold\n",
    "            # note: \"linalg.lstsq(a,b)\" is substitue for Matlab's left division operator \"\\\"\n",
    "            lambdaI = lambdas[l] * np.eye(M)\n",
    "            lambdaI[0,0] = 0 # remove bias regularization\n",
    "            w[:,k_2,l] = np.linalg.solve(XtX+lambdaI,Xty).squeeze()\n",
    "            # Evaluate training and test performance\n",
    "            Eval_rlr[k_2,l] = np.power(y_val-X_val_rlr @ w[:,k_2,l].T,2).mean(axis=0)\n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "        k_2 = k_2 + 1\n",
    "        print(f\"k_2: {k_2}\")\n",
    "\n",
    "        \n",
    "        \n",
    "           \n",
    "\n",
    "    #ANN    \n",
    "    h_index = 0\n",
    "    for h in h_values:  \n",
    "        Egen_ANN_temp[h_index] = np.dot(size_val, Eval_ANN[:, h_index])/size_par[k_1]\n",
    "        h_index = h_index + 1\n",
    "    h_opti = h_values[int(np.argmin(Egen_ANN_temp))]  #choice of parameter\n",
    "    optimal_ANN[k_1] = h_opti \n",
    "    \n",
    "    # Define the model\n",
    "    model = lambda: torch.nn.Sequential(\n",
    "            torch.nn.Linear(M,h_opti), #M features to n_hidden_units\n",
    "            torch.nn.Tanh(),   # 1st transfer function,\n",
    "            torch.nn.Linear(h_opti, 1), # n_hidden_units to 1 output neuron\n",
    "            Squeeze() # remove the extra dimension\n",
    "            ) \n",
    "    #Train the model\n",
    "    net, final_loss, learning_curve = train_neural_net(model,\n",
    "                                                        loss_fn,\n",
    "                                                        X=X_par_ANN,\n",
    "                                                        y=y_par_ANN,\n",
    "                                                        n_replicates=n_replicates,\n",
    "                                                        max_iter=max_iter)\n",
    "    #Test model\n",
    "    y_test_est_ANN = net(X_test_ANN)\n",
    "    # Determine errors and errors\n",
    "    se = (y_test_est_ANN.float()-y_test_ANN.float())**2 # squared error\n",
    "    Etest_ANN[k_1] = (sum(se).type(torch.float)/len(y_test)).data.numpy() #mean \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Linear regression\n",
    "    for l in range(0,len(lambdas)):\n",
    "        Egen_rlr_temp[l] = np.dot(size_val, Eval_rlr[:, l])/size_par[k_1]\n",
    "    opt_lambda[k_1] = lambdas[np.argmin(Egen_rlr_temp)]\n",
    "    #we should obtain the same kfold than for the rest since the function used inside rlr_validate\n",
    "    #is the same\n",
    "    \n",
    "    mu[k_1, :] = np.mean(X_par[:, 1:], 0)\n",
    "    sigma[k_1, :] = np.std(X_par[:, 1:], 0)\n",
    "    \n",
    "    X_par_rlr[:, 1:] = (X_par[:, 1:] - mu[k_1, :] ) / sigma[k_1, :] \n",
    "    X_test_rlr[:, 1:] = (X_test[:, 1:] - mu[k_1, :] ) / sigma[k_1, :] \n",
    "    \n",
    "    Xty = X_par_rlr.T @ y_par\n",
    "    XtX = X_par_rlr.T @ X_par_rlr\n",
    "    \n",
    "    lambdaI = opt_lambda[k_1] * np.eye(M)\n",
    "    lambdaI[0,0] = 0 # Do no regularize the bias term\n",
    "    w_rlr[:,k_1] = np.linalg.solve(XtX+lambdaI,Xty).squeeze()\n",
    "    Error_test_rlr[k_1] = np.square(y_test-X_test_rlr @ w_rlr[:,k_1]).sum(axis=0)/y_test.shape[0]\n",
    "    \n",
    "    \n",
    "    #baseline\n",
    "    Etest_nofeatures[k_1] = np.square(y_test-y_par.mean()).sum()/y_test.shape[0]\n",
    "    #DIVISER PAR TEST\n",
    "                  \n",
    "    k_1 = k_1 + 1\n",
    "    print(f\"k_1: {k_1}\")\n",
    "    \n",
    "# %%\n",
    "\n",
    "#Final generalisation error baseline\n",
    "Egen_nofeatures = np.dot(size_test,  Etest_nofeatures)/N     \n",
    "#Final generalisation error ANN\n",
    "Egen_ANN  = np.dot(size_test, Etest_ANN)/N\n",
    "#Final generalisation error rlr\n",
    "Egen_rlr = np.dot(size_test, Error_test_rlr)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        th {\n",
       "            text-align: center;\n",
       "        }\n",
       "    </style>\n",
       "<style type=\"text/css\">\n",
       "#T_45778_row0_col0, #T_45778_row0_col1, #T_45778_row0_col2, #T_45778_row0_col3, #T_45778_row0_col4, #T_45778_row0_col5, #T_45778_row1_col0, #T_45778_row1_col1, #T_45778_row1_col2, #T_45778_row1_col3, #T_45778_row1_col4, #T_45778_row1_col5, #T_45778_row2_col0, #T_45778_row2_col1, #T_45778_row2_col2, #T_45778_row2_col3, #T_45778_row2_col4, #T_45778_row2_col5, #T_45778_row3_col0, #T_45778_row3_col1, #T_45778_row3_col2, #T_45778_row3_col3, #T_45778_row3_col4, #T_45778_row3_col5, #T_45778_row4_col0, #T_45778_row4_col1, #T_45778_row4_col2, #T_45778_row4_col3, #T_45778_row4_col4, #T_45778_row4_col5 {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_45778\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_45778_level0_col0\" class=\"col_heading level0 col0\" >Outer fold</th>\n",
       "      <th id=\"T_45778_level0_col1\" class=\"col_heading level0 col1\" colspan=\"2\">ANN</th>\n",
       "      <th id=\"T_45778_level0_col3\" class=\"col_heading level0 col3\" colspan=\"2\">Linear Regression</th>\n",
       "      <th id=\"T_45778_level0_col5\" class=\"col_heading level0 col5\" >Baseline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank level1\" >&nbsp;</th>\n",
       "      <th id=\"T_45778_level1_col0\" class=\"col_heading level1 col0\" >i</th>\n",
       "      <th id=\"T_45778_level1_col1\" class=\"col_heading level1 col1\" >h<sub>i</sub><sup>*</sup></th>\n",
       "      <th id=\"T_45778_level1_col2\" class=\"col_heading level1 col2\" >E<sub>i</sub><sup>test</sup></th>\n",
       "      <th id=\"T_45778_level1_col3\" class=\"col_heading level1 col3\" >&lambda;<sub>i</sub><sup>*</sup></th>\n",
       "      <th id=\"T_45778_level1_col4\" class=\"col_heading level1 col4\" >E<sub>i</sub><sup>test</sup></th>\n",
       "      <th id=\"T_45778_level1_col5\" class=\"col_heading level1 col5\" >E<sub>i</sub><sup>test</sup></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_45778_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_45778_row0_col0\" class=\"data row0 col0\" >1.00</td>\n",
       "      <td id=\"T_45778_row0_col1\" class=\"data row0 col1\" >75.00</td>\n",
       "      <td id=\"T_45778_row0_col2\" class=\"data row0 col2\" >0.09</td>\n",
       "      <td id=\"T_45778_row0_col3\" class=\"data row0 col3\" >10.00</td>\n",
       "      <td id=\"T_45778_row0_col4\" class=\"data row0 col4\" >0.55</td>\n",
       "      <td id=\"T_45778_row0_col5\" class=\"data row0 col5\" >0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45778_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_45778_row1_col0\" class=\"data row1 col0\" >2.00</td>\n",
       "      <td id=\"T_45778_row1_col1\" class=\"data row1 col1\" >75.00</td>\n",
       "      <td id=\"T_45778_row1_col2\" class=\"data row1 col2\" >0.10</td>\n",
       "      <td id=\"T_45778_row1_col3\" class=\"data row1 col3\" >10.00</td>\n",
       "      <td id=\"T_45778_row1_col4\" class=\"data row1 col4\" >0.60</td>\n",
       "      <td id=\"T_45778_row1_col5\" class=\"data row1 col5\" >1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45778_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_45778_row2_col0\" class=\"data row2 col0\" >3.00</td>\n",
       "      <td id=\"T_45778_row2_col1\" class=\"data row2 col1\" >100.00</td>\n",
       "      <td id=\"T_45778_row2_col2\" class=\"data row2 col2\" >0.10</td>\n",
       "      <td id=\"T_45778_row2_col3\" class=\"data row2 col3\" >10.00</td>\n",
       "      <td id=\"T_45778_row2_col4\" class=\"data row2 col4\" >0.55</td>\n",
       "      <td id=\"T_45778_row2_col5\" class=\"data row2 col5\" >1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45778_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_45778_row3_col0\" class=\"data row3 col0\" >4.00</td>\n",
       "      <td id=\"T_45778_row3_col1\" class=\"data row3 col1\" >75.00</td>\n",
       "      <td id=\"T_45778_row3_col2\" class=\"data row3 col2\" >0.10</td>\n",
       "      <td id=\"T_45778_row3_col3\" class=\"data row3 col3\" >10.00</td>\n",
       "      <td id=\"T_45778_row3_col4\" class=\"data row3 col4\" >0.56</td>\n",
       "      <td id=\"T_45778_row3_col5\" class=\"data row3 col5\" >0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45778_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_45778_row4_col0\" class=\"data row4 col0\" >5.00</td>\n",
       "      <td id=\"T_45778_row4_col1\" class=\"data row4 col1\" >100.00</td>\n",
       "      <td id=\"T_45778_row4_col2\" class=\"data row4 col2\" >0.12</td>\n",
       "      <td id=\"T_45778_row4_col3\" class=\"data row4 col3\" >10.00</td>\n",
       "      <td id=\"T_45778_row4_col4\" class=\"data row4 col4\" >0.59</td>\n",
       "      <td id=\"T_45778_row4_col5\" class=\"data row4 col5\" >1.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%% Tableau\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Visualizza i risultati\n",
    "\n",
    "# Crea un MultiIndex per le colonne\n",
    "columns = pd.MultiIndex.from_tuples([\n",
    "    ('Outer fold', 'i'),\n",
    "    ('ANN', 'h<sub>i</sub><sup>*</sup>'),\n",
    "    ('ANN', 'E<sub>i</sub><sup>test</sup>'),\n",
    "    ('Linear Regression', '&lambda;<sub>i</sub><sup>*</sup>'),\n",
    "    ('Linear Regression', 'E<sub>i</sub><sup>test</sup>'),\n",
    "    ('Baseline', 'E<sub>i</sub><sup>test</sup>')\n",
    "])\n",
    "outer_fold_i = np.reshape(range(1, K1 + 1), (K1))\n",
    "opt_lambda = np.reshape(opt_lambda, (K1))\n",
    "Error_test_rlr = np.reshape(Error_test_rlr, (K1))\n",
    "Etest_nofeatures = np.reshape(Etest_nofeatures, (K1))\n",
    "\n",
    "# Convert lists to pandas Series before applying the format() function\n",
    "dff = pd.DataFrame(list(zip(pd.Series(outer_fold_i), pd.Series(optimal_ANN), pd.Series(Etest_ANN), pd.Series(opt_lambda), pd.Series(Error_test_rlr), pd.Series(Etest_nofeatures))), columns=columns)\n",
    "\n",
    "    \n",
    "# Apply the format() function\n",
    "df_styled = dff.style.set_properties(**{'text-align': 'center'}).format(\"{:.2f}\")\n",
    "\n",
    "# Aggiungi CSS personalizzato per allineare le intestazioni delle colonne\n",
    "styles = \"\"\"\n",
    "    <style>\n",
    "        th {\n",
    "            text-align: center;\n",
    "        }\n",
    "    </style>\n",
    "\"\"\"\n",
    "\n",
    "# Visualizza il DataFrame come HTML\n",
    "display(HTML(styles + df_styled.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.2616369\t0.00066750584\n",
      "\t\t2000\t0.13133186\t0.00034593904\n",
      "\t\tFinal loss:\n",
      "\t\t2954\t0.1050786\t2.8361924e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.25474727\t0.0007226959\n",
      "\t\t2000\t0.12429067\t0.00026195013\n",
      "\t\tFinal loss:\n",
      "\t\t2616\t0.109403364\t3.4050979e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.25570196\t0.00084148895\n",
      "\t\t2000\t0.13211924\t0.00035819184\n",
      "\t\t3000\t0.10417718\t0.00018720001\n",
      "\t\t4000\t0.08800165\t0.0001603281\n",
      "\t\t5000\t0.078984976\t0.00019145139\n",
      "\t\tFinal loss:\n",
      "\t\t5000\t0.078984976\t0.00019145139\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.24185304\t0.0009591246\n",
      "\t\t2000\t0.12226812\t0.00026500315\n",
      "\t\tFinal loss:\n",
      "\t\t2847\t0.102186754\t8.749362e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.26220924\t0.0006075902\n",
      "\t\t2000\t0.13155824\t0.0002914634\n",
      "\t\t3000\t0.10311162\t0.00019874069\n",
      "\t\t4000\t0.08751246\t0.00012627465\n",
      "\t\tFinal loss:\n",
      "\t\t4013\t0.08728338\t1.7072166e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t56\t0.56228983\t4.240135e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.26203924\t0.0007173632\n",
      "\t\t2000\t0.12897988\t0.00036736878\n",
      "\t\t3000\t0.10080665\t0.00014306854\n",
      "\t\tFinal loss:\n",
      "\t\t3922\t0.0864072\t8.622646e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t33\t0.571201\t9.391462e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.24838513\t0.0007975591\n",
      "\t\t2000\t0.123927325\t0.0004228294\n",
      "\t\tFinal loss:\n",
      "\t\t2600\t0.10470498\t2.8463145e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.25117785\t0.0007952731\n",
      "\t\t2000\t0.12732488\t0.0006195376\n",
      "\t\t3000\t0.101150095\t0.00019994329\n",
      "\t\t4000\t0.084982134\t0.00015007248\n",
      "\t\tFinal loss:\n",
      "\t\t4762\t0.078055896\t2.8635566e-07\n",
      "\n",
      "Linear regresssion vs. ANN\n",
      "z = mean(Z_A-Z_B) estimator 0.36611162671893743  CI:  (0.354975763761482, 0.3772474896763929) p-value 0.0\n",
      "\n",
      "\n",
      "ANN vs. Baseline\n",
      "z = mean(Z_A-Z_B) estimator -0.7975733276789282  CI:  (-0.8140346988041148, -0.7811119565537415) p-value 0.0\n",
      "\n",
      "\n",
      "Linear  Regression vs. Baseline\n",
      "z = mean(Z_A-Z_B) estimator -0.4314617009599907  CI:  (-0.4460718655954963, -0.41685153632448513) p-value 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %% Statistical comparison\n",
    "\n",
    "import numpy as np, scipy.stats as st\n",
    "\n",
    "K = 10\n",
    "CV = model_selection.KFold(K,shuffle=True)\n",
    "\n",
    "# store predictions.\n",
    "yhat = []\n",
    "y_true = []\n",
    "i=0\n",
    "for train_index, test_index in CV.split(X, y): \n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train = X[train_index,:]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index,:]\n",
    "    y_test = y[test_index]\n",
    "    X_train_rlr_stat = X[train_index,:]\n",
    "    X_test_rlr_stat = X[test_index,:]\n",
    "    X_train_ANN = torch.from_numpy(X_train).float()\n",
    "    y_train_ANN = torch.from_numpy(y_train).float()\n",
    "    X_test_ANN = torch.from_numpy(X_test).float()\n",
    "    y_test_ANN = torch.from_numpy(y_test).float()\n",
    "    \n",
    "\n",
    "    # Fit classifier and classify the test points (consider 1 to 40 neighbors)\n",
    "    dy = []\n",
    "    \n",
    "    # linear regression \n",
    "    # trova lambda_star come il parametro di controllo ottimale\n",
    "    index = np.argmin(Error_test_rlr)\n",
    "    lambda_star = opt_lambda[index]\n",
    "    mu_rlr = np.mean(X_train[:, 1:], 0)\n",
    "    sigma_rlr = np.std(X_train[:, 1:], 0)\n",
    "    X_train_rlr_stat[:, 1:] = (X_train[:, 1:] - mu_rlr) / sigma_rlr\n",
    "    X_test_rlr_stat[:, 1:] = (X_test[:, 1:] - mu_rlr) / sigma_rlr\n",
    "    \n",
    "    Xty = X_train_rlr_stat.T @ y_train\n",
    "    XtX = X_train_rlr_stat.T @ X_train_rlr_stat\n",
    "    \n",
    "    # Compute parameters for current value of lambda and current CV fold\n",
    "    # note: \"linalg.lstsq(a,b)\" is substitue for Matlab's left division operator \"\\\"\n",
    "    lambdaI = lambda_star * np.eye(M)\n",
    "    lambdaI[0,0] = 0 # remove bias regularization\n",
    "    w_rlr_stat = np.linalg.solve(XtX+lambdaI,Xty).squeeze()\n",
    "    y_est = X_test_rlr_stat @ w_rlr_stat\n",
    "    dy.append( y_est )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ann\n",
    "    h_star = 500\n",
    "    model = lambda: torch.nn.Sequential(\n",
    "            torch.nn.Linear(M, h_star), #M features to n_hidden_units\n",
    "            torch.nn.Tanh(),   # 1st transfer function,\n",
    "            torch.nn.Linear(h_star, 1), # n_hidden_units to 1 output neuron\n",
    "            Squeeze() # remove the extra dimension\n",
    "            ) \n",
    "    # Train the model\n",
    "    net, final_loss, learning_curve = train_neural_net(model,\n",
    "                                                      loss_fn,\n",
    "                                                      X=X_train_ANN,\n",
    "                                                      y=y_train_ANN,\n",
    "                                                      n_replicates=n_replicates,\n",
    "                                                      max_iter=max_iter)\n",
    "    # Test model\n",
    "    y_est = net(X_test_ANN).detach().numpy()\n",
    "    dy.append( y_est )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # baseline\n",
    "    y_est = y_train.mean()*np.ones(len(y_test)) \n",
    "    dy.append( y_est )\n",
    "\n",
    "\n",
    "    dy = np.stack(dy, axis=1)\n",
    "    yhat.append(dy)\n",
    "    y_true.append(y_test)\n",
    "    i+=1\n",
    "\n",
    "yhat = np.concatenate(yhat)\n",
    "y_true = np.concatenate(y_true)\n",
    "\n",
    "\n",
    "## Confidence interval test\n",
    "\n",
    "# %%\n",
    "# Significance level used for the statistical tests\n",
    "alpha = 0.05\n",
    "\n",
    "# First comparison\n",
    "zA = np.abs(y_true - yhat[:,0] ) ** 2\n",
    "zB = np.abs(y_true - yhat[:,1] ) ** 2\n",
    "\n",
    "z = zA - zB\n",
    "CI = st.t.interval(1-alpha, len(z)-1, loc=np.mean(z), scale=st.sem(z))  # Confidence interval\n",
    "p = 2*st.t.cdf( -np.abs( np.mean(z) )/st.sem(z), df=len(z)-1)  # p-value\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Linear regresssion vs. ANN\")\n",
    "print(\"z = mean(Z_A-Z_B) estimator\", z.mean(), \" CI: \", CI, \"p-value\", p)\n",
    "print()\n",
    "\n",
    "# Second comparison\n",
    "zA = np.abs(y_true - yhat[:,1] ) ** 2\n",
    "zB = np.abs(y_true - yhat[:,2] ) ** 2\n",
    "\n",
    "z = zA - zB\n",
    "CI = st.t.interval(1-alpha, len(z)-1, loc=np.mean(z), scale=st.sem(z))  # Confidence interval\n",
    "p = 2*st.t.cdf( -np.abs( np.mean(z) )/st.sem(z), df=len(z)-1)  # p-value\n",
    "\n",
    "print()\n",
    "print(\"ANN vs. Baseline\")\n",
    "print(\"z = mean(Z_A-Z_B) estimator\", z.mean(), \" CI: \", CI, \"p-value\", p)\n",
    "print()\n",
    "\n",
    "# Third comparison\n",
    "zA = np.abs(y_true - yhat[:,0] ) ** 2\n",
    "zB = np.abs(y_true - yhat[:,2] ) ** 2\n",
    "\n",
    "z = zA - zB\n",
    "CI = st.t.interval(1-alpha, len(z)-1, loc=np.mean(z), scale=st.sem(z))  # Confidence interval\n",
    "p = 2*st.t.cdf( -np.abs( np.mean(z) )/st.sem(z), df=len(z)-1)  # p-value\n",
    "\n",
    "print()\n",
    "print(\"Linear  Regression vs. Baseline\")\n",
    "print(\"z = mean(Z_A-Z_B) estimator\", z.mean(), \" CI: \", CI, \"p-value\", p) \n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results from previous cell (statistical comparison)\n",
    "\n",
    "Linear regresssion vs. ANN\n",
    "z = mean(Z_A-Z_B) estimator 0.36611162671893743  CI:  (0.354975763761482, 0.3772474896763929) p-value 0.0\n",
    "\n",
    "\n",
    "ANN vs. Baseline\n",
    "z = mean(Z_A-Z_B) estimator -0.7975733276789282  CI:  (-0.8140346988041148, -0.7811119565537415) p-value 0.0\n",
    "\n",
    "\n",
    "Linear  Regression vs. Baseline\n",
    "z = mean(Z_A-Z_B) estimator -0.4314617009599907  CI:  (-0.4460718655954963, -0.41685153632448513) p-value 0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course02450",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
